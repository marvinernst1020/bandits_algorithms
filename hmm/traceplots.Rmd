---
title: "Sanity checks"
output: html_document
date: "2025-05-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rjags)
library(coda)
library(tidyverse)
library(here)
library(nimble)
library(glue)
library(future.apply)
plan(multisession)
library(ggmcmc)
library(dplyr)
library(ggplot2)

output_dir <- "plots"
```


# Problem Setup: Global Latent State

We simulate a $K$-armed bandit problem where **all arms share the same underlying latent state process** governed by a Hidden Markov Model (HMM). This represents a scenario where there's a common environment or external condition that affects the reward probability of all arms.

### Loading all the Models and Functions
```{r}
source(here("src/load_all.R"))
```

Setting a seed:
```{r}
set.seed(123)
```

---

# GLOABL SETTING

Number of arms:
```{r}
K <- 2 
```

Number of time steps:
```{r}
N <- 10000
```

Transition Probability:
```{r}
pi_global <- matrix(c(0.999, 0.001,
                     0.001, 0.999),
                     nrow = 2, byrow = TRUE)  
```

Probability of Reward:
```{r}
mu <- matrix(c(0.95, 0.1,
               0.1, 0.95),
                nrow = K, byrow = TRUE)
```

---

# 1. Generating Ground Truth Data for Global State

## 1.1 Simulate Ground Truth

For only one Run:
```{r simulate-global-state}
generate_global_datasets(
  K = K,
  N = N,
  mu = mu,
  pi_global = pi_global,
  n_runs = 1,
  scenario_name = "single_run",
  root_path = "data_global"
)
```

Load the generated data:
```{r}
truth <- readRDS("data_global/single_run/global_truth_1.rds")
y_global <- truth$y
z_global <- truth$z
```

```{r}
model_path <- advanced_model_path
post_matrix <- NULL

z_true <- z_global
y_true <- y_global
dynamics<-'common'
batch_size <- 100
burn = 1
n_iter = 1200

data_track <-list()
  
# we generate a full observability setting where model can use all information
  for (t in 2:N) {
    
    if (t %% batch_size == 0) {
      data_list <- list(
        y_obs = y_global[, 1:(t-1)],
        K = K,
        N = t - 1
      )
      
      data_track[[t/batch_size]] <- data_list
    }
  }
```

Now we do the inference for an increasing number of observations:

```{r}
# Parameters
param_names <- c("mu", "pi")

# Result list for ggmcmc
gg_data_all <- list()

# Loop through data_track list
for (i in seq_along(data_track)) {
  cat("Running model for dataset", i, "\n")
  
  model <- jags.model(model_path, data = data_track[[i]], n.chains = 1, quiet = TRUE)
  update(model, burn) # we set 1 burn in sample as example
  
  post <- coda.samples(model, variable.names = param_names, n.iter = n_iter) 
  
  # Convert to ggmcmc data frame and tag with dataset id
  gg_data <- ggs(post)
  gg_data$dataset <- paste0("Dataset ", i)
  gg_data_all[[i]] <- gg_data
}

# Combine all datasets
gg_data_combined <- bind_rows(gg_data_all)

```

Now we compute the mean of the posterior samples
```{r}
means_df <- gg_data_combined %>%
  filter(Iteration > 1000) %>% 
  mutate(run = as.integer(gsub("Dataset ", "", dataset))) %>%
  group_by(Chain, Parameter,run) %>%
  summarise(mean_value = mean(value), .groups = "drop")

unique_runs <- unique(means_df$run)

for (r in unique_runs) {
  
  mu11 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[1,1]"]
  mu12 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[1,2]"]
  mu21 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[2,1]"]
  mu22 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[2,2]"]
  
  if (mu11 < mu12) {
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[1,1]"] <- mu12
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[1,2]"] <- mu11
  }
  
  if (mu22 < mu21) {
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[2,2]"] <- mu21
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu[2,1]"] <- mu22
  }
  
  
}

ref_lines <- data.frame(
  Parameter = c("mu[1,1]", "mu[1,2]","mu[2,1]","mu[2,2]", "pi[1]", "pi[2]"),
  ref_value = c(mu[1,1],mu[1,2],mu[2,1],mu[2,2], pi_global[1,2], pi_global[2,2])  # your true values
)


global_means<-ggplot(means_df, aes(x = run, y = mean_value)) +
  geom_line(alpha = 0.7, linewidth = 0.9, color = 'black') +
  geom_hline(data = ref_lines, aes(yintercept = ref_value), 
             linetype = "dashed", color = "red") +
  facet_wrap(~ Parameter, scales = "free_y") +
  labs(
    #title = "Posterior Means of Parameters Across Runs",
    x     = "Batch Index",
    y     = "Posterior Mean"
  ) +
  theme_classic(base_size = 12) +
  theme(
    legend.position = "none"
  )

ggsave(file.path(output_dir, "global_means.png"), plot = global_means, width = 8, height = 6, dpi = 300)

```


Now we plot the trace plots for the last batch:

```{r}

last_gg_data <- gg_data_all[[length(gg_data_all)]]

unique_it <- unique(last_gg_data$Iteration)

for (r in unique_it) {
  
  mu11 <- last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[1,1]"]
  mu12 <- last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[1,2]"]
  mu21 <- last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[2,1]"]
  mu22 <- last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[2,2]"]
  
  if (mu11 < mu12) {
    last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[1,1]"] <- mu12
    last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[1,2]"] <- mu11
  }
  
  if (mu22 < mu21) {
    last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[2,2]"] <- mu21
    last_gg_data$value[last_gg_data$Iteration == r & last_gg_data$Parameter == "mu[2,1]"] <- mu22
  }
  
  
}

global_last<-ggplot(last_gg_data, aes(x = Iteration, y = value)) +
  geom_line(alpha = 0.7, size = 0.9, color = 'black') +
   geom_hline(data = ref_lines, aes(yintercept = ref_value), 
             linetype = "dashed", color = "red") +
  facet_wrap(~Parameter, scales = "free_y") +
  labs(
    x = "Sample",
    y = "Parameter Value"
  ) +
  theme_classic(base_size = 12) +
  theme(
    legend.position = "none"
  )

ggsave(file.path(output_dir, "global_last.png"), plot = global_last, width = 8, height = 6, dpi = 300)
```

We check if state sequence is well infered:
```{r}
burn = 1000
n_iter = 200

# Parameters
z_names <- paste0("z[", 1:data_track[[length(data_track)]]$N, "]")
param_names <- c("mu", "pi",z_names)

model <- jags.model(model_path, data = data_track[[length(data_track)]], n.chains = 1, quiet = TRUE)
update(model, burn) 
  
post <- coda.samples(model, variable.names = param_names, n.iter = n_iter) 
```

```{r}
posterior_matrix <- as.matrix(post)
# Extract only the columns that match "z["
z_cols <- grep("^z\\[", colnames(posterior_matrix), value = TRUE)

# Compute means for each z[i]
z_means <- colMeans(posterior_matrix[, z_cols])

# Extract numeric indices from names like "z[1]", "z[2]", ...
z_indices <- as.numeric(gsub("z\\[(\\d+)\\]", "\\1", names(z_means)))

# Order by index
ordered_means <- z_means[order(z_indices)]

df <- data.frame(
  i = sort(z_indices),
  mean_z = ordered_means
)

ggplot(df, aes(x = i, y = mean_z)) +
  geom_point() +
  labs(x = "Time", y = "State ") +
  theme_minimal()

df_true <- data.frame(i = seq_along(z_global), value = z_global)
```
```{r}
library(ggplot2)
library(gridExtra)

# -------------------------------------------------------------------
# Assume:
#   • `post` is a coda::mcmc or mcmc.list object containing samples with columns "z[1]", "z[2]", ..., "z[N]".
#   • `z_global` is a length-N vector of true latent states.
#   • `N` is the length of `z_global`.
# -------------------------------------------------------------------

# 1) Convert MCMC object `post` to a plain matrix:
posterior_matrix <- as.matrix(post)

# 2) Pick out only the “z[t]” columns and compute their posterior means:
z_cols   <- grep("^z\\[", colnames(posterior_matrix), value = TRUE)
z_means  <- colMeans(posterior_matrix[, z_cols, drop = FALSE])

# 3) Recover integer “t” from names like "z[7]" → 7:
z_indices     <- as.integer(gsub("^z\\[(\\d+)\\]$", "\\1", names(z_means)))
ordering      <- order(z_indices)
ordered_idx   <- z_indices[ordering]
ordered_means <- z_means[ordering]

# 4) Build a data.frame for posterior‐mean predictions:
df_post <- data.frame(
  Time  = ordered_idx,
  MeanZ = ordered_means
)

# 5) Build a data.frame for the true latent sequence:
df_true <- data.frame(
  Time  = seq_len(N),
  TrueZ = z_global
)

# 6A) “Posterior Mean” plot (no grid background, larger title)
p_post <- ggplot(df_post, aes(x = Time, y = MeanZ)) +
  geom_point(color = "black", size = 1) +
  labs(
    title = "Posterior Mean of P(z[t] = 1)",
    x     = "Time",
    y     = "Predicted State"
  ) +
  theme_classic(base_size = 12) 

# 6B) “True State” plot (no grid background, larger title)
p_true <- ggplot(df_true, aes(x = Time, y = TrueZ)) +
  geom_point(color = "black", size = 1) +
  labs(
    title = "True Latent State z[t]",
    x     = "Time",
    y     = "True State"
  ) +
  theme_classic(base_size = 12) 

# 7) Arrange side by side
grid.arrange(
  p_post,
  p_true,
  ncol = 2
)
```



# The Local Setup

Transition Probabilities (one per arm):

```{r}
pi_list <- list(
  matrix(c(0.999, 0.001,
           0.001, 0.999), nrow = 2, byrow = TRUE),  
  matrix(c(0.999, 0.001,
           0.001, 0.999),, nrow = 2, byrow = TRUE)  
)
```

Reward Probabilities:

```{r}
mu <- matrix(c(0.95, 0.1,
               0.1, 0.95), nrow = K, byrow = TRUE)
```

---

## Simulate Ground Truth

Generate and save a single local dataset:

```{r}
generate_local_datasets(K = K, N = N, mu = mu, pi_list = pi_list, n_runs = 1, scenario_name = "single_run", root_path = "data_local")
```

Load the generated data:
```{r}
truth <- readRDS("data_local/single_run/local_truth_1.rds")
y_local <- truth$y
z_local <- truth$z
```


Inference with full observability:
```{r}
library(rjags)
library(coda)
library(ggmcmc)

model_path <- poor_model_path
batch_size <- 100
burn       <- 1
n_iter     <- 1200

K <- nrow(mu)     
N <- 10000
n_batches <- floor(N / batch_size)


gg_data_all <- vector("list", length = n_batches)


for (t in seq_len(N)) {
  if (t %% batch_size == 0) {
    batch_index <- t / batch_size
    cat("Running batch", batch_index, "(data up to time step", t - 1, ")\n")
    
    arm_results <- vector("list", length = K)
    for (k in seq_len(K)) {
      data_list <- list(
        y = y_local[k, 1:(t - 1)],  # all rewards of arm k up to time t–1
        N = t - 1
      )
      model_k <- rjags::jags.model(
        file     = model_path,
        data     = data_list,
        n.chains = 1,
        quiet    = TRUE
      )
      update(model_k, burn)

      post_k <- rjags::coda.samples(
        model          = model_k,
        variable.names = c("mu0", "mu1", "pi"),
        n.iter         = n_iter
      )

      gg_k       <- ggs(post_k)
      gg_k$dataset <- paste0("Dataset ", batch_index)
      gg_k$arm     <- k

      arm_results[[k]] <- gg_k
    }
    
    gg_data_all[[batch_index]] <- arm_results
  }
}

gg_data_k1 <- vector("list", length = n_batches)
gg_data_k2 <- vector("list", length = n_batches)

for (b in seq_len(n_batches)) {
  gg_data_k1[[b]] <- gg_data_all[[b]][[1]]
  gg_data_k2[[b]] <- gg_data_all[[b]][[2]]
}
```

```{r}
gg_data_k1
```



```{r}

gg_data_combined1 <- bind_rows(gg_data_k1)


means_df <- gg_data_combined1 %>%
  filter(Iteration > 1000) %>% 
  mutate(run = as.integer(gsub("Dataset ", "", dataset))) %>%
  group_by(run, Chain, Parameter) %>%
  summarise(mean_value = mean(value), .groups = "drop")

unique_runs <- unique(means_df$run)

for (r in unique_runs) {
  
  mu0 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu0"]
  mu1 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu1"]
  
  if (mu0 < mu1) {
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu0"] <- mu1
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu1"] <- mu0
  }
}

ref_lines1 <- data.frame(
  Parameter = c("mu0", "mu1", "pi[1]", "pi[2]"),
  ref_value = c(mu[1,1],mu[1,2], pi_list[[1]][1,2], pi_list[[1]][2,2])  # your true values
)

local_means_arm1<-ggplot(means_df, aes(x = run, y = mean_value)) +
  geom_line(alpha = 0.7, size = 0.9, color = 'black') +
  geom_hline(data = ref_lines1, aes(yintercept = ref_value), 
             linetype = "dashed", color = "red") +
  facet_wrap(~ Parameter, scales = "free_y") +
  labs(
    x     = "Run (batch index)",
    y     = "Posterior Mean"
  ) +
  theme_classic(base_size = 12) +
  theme(
    legend.position = "none"
  )

ggsave(file.path(output_dir, "local_means_arm1.png"), plot = local_means_arm1, width = 8, height = 6, dpi = 300)
```

```{r}
local_means_arm1
```


```{r}

gg_data_combined2 <- bind_rows(gg_data_k2)


means_df <- gg_data_combined2 %>%
  filter(Iteration > 1000) %>% 
  mutate(run = as.integer(gsub("Dataset ", "", dataset))) %>%
  group_by(run, Chain, Parameter) %>%
  summarise(mean_value = mean(value), .groups = "drop")

unique_runs <- unique(means_df$run)

for (r in unique_runs) {
  
  mu0 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu0"]
  mu1 <- means_df$mean_value[means_df$run == r & means_df$Parameter == "mu1"]
  
  if (mu0 < mu1) {
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu0"] <- mu1
    means_df$mean_value[means_df$run == r & means_df$Parameter == "mu1"] <- mu0
  }
}

ref_lines2 <- data.frame(
  Parameter = c("mu0", "mu1", "pi[1]", "pi[2]"),
  ref_value = c(mu[2,1],mu[2,2], pi_list[[2]][1,2], pi_list[[2]][2,2])  # your true values
)

local_means_arm2<-ggplot(means_df, aes(x = run, y = mean_value)) +
  geom_line(alpha = 0.7, size = 0.9, color = 'black') +
  geom_hline(data = ref_lines1, aes(yintercept = ref_value), 
             linetype = "dashed", color = "red") +
  facet_wrap(~ Parameter, scales = "free_y") +
  labs(
    x     = "Run (batch index)",
    y     = "Posterior Mean"
  ) +
  theme_classic(base_size = 12) +
  theme(
    legend.position = "none"
  )

ggsave(file.path(output_dir, "local_means_arm2.png"), plot = local_means_arm2, width = 8, height = 6, dpi = 300)
```

```{r}
local_means_arm2
```



We check if state sequence is well infered:
```{r}
posts <- vector("list", length = K)
for (k in seq_len(K)) {
  cat("Inferring z[ ] for arm", k, "\n")
  
  data_list_k <- list(
    y = y_local[k, 1:N],
    N = N
  )
  
  model_k <- rjags::jags.model(
    file     = poor_model_path,
    data     = data_list_k,
    n.chains = 1,
    quiet    = TRUE
  )
  update(model_k, burn)
  
  # request all z[1:N] + mu0, mu1, pi
  z_names_k     <- paste0("z[", 1:N, "]")
  param_names_k <- c("mu0", "mu1", "pi", z_names_k)
  
  post_k <- rjags::coda.samples(
    model          = model_k,
    variable.names = param_names_k,
    n.iter         = n_iter
  )
  posts[[k]] <- post_k
}
```

```{r}
library(ggplot2)
library(gridExtra)


all_plots <- list()

for (k in seq_len(K)) {

  post_k           <- posts[[k]]
  posterior_matrix <- as.matrix(post_k)

  z_cols   <- grep("^z\\[", colnames(posterior_matrix), value = TRUE)
  z_means  <- colMeans(posterior_matrix[, z_cols, drop = FALSE])

  z_indices   <- as.integer(sub("^z\\[(\\d+)\\]$", "\\1", names(z_means)))
  ordering    <- order(z_indices)
  ordered_idx <- z_indices[ordering]
  ordered_means <- z_means[ordering]

  truth_seq   <- z_local[k, ordered_idx]
  correlation <- cor(ordered_means, truth_seq)
  if (!is.na(correlation) && correlation < 0) {
    ordered_means <- 1 - ordered_means
  }

  df_post <- data.frame(
    Time  = ordered_idx,
    MeanZ = ordered_means
  )
  df_true <- data.frame(
    Time  = seq_len(N),
    TrueZ = z_local[k, ]
  )

  p_post <- ggplot(df_post, aes(x = Time, y = MeanZ)) +
    geom_point(color = "black", size = 1) +
    labs(
      title = paste0("Arm ", k, ": Posterior Mean of P(z[t]=1)"),
      plot.title   = element_text(size = 9),
      x     = "Time t",
      y     = expression(P(z[t] == 1 ~"|"~ data))
    ) +
    theme_classic(base_size = 12)

  p_true <- ggplot(df_true, aes(x = Time, y = TrueZ)) +
    geom_point(color = "black", size = 0.8) +
    labs(
      title = paste0("Arm ", k, ": True z[t]"),
      x     = "Time t",
      y     = "z[t]"
    ) +
    theme_classic(base_size = 12)


  all_plots[[2*k - 1]] <- p_post
  all_plots[[2*k    ]] <- p_true
}

grid.arrange(
  grobs = all_plots,
  ncol  = 2
)
```
```{r}
library(ggplot2)
library(gridExtra)


all_plots <- list()

for (k in seq_len(K)) {
  post_k           <- posts[[k]]
  posterior_matrix <- as.matrix(post_k)

  z_cols   <- grep("^z\\[", colnames(posterior_matrix), value = TRUE)
  z_means  <- colMeans(posterior_matrix[, z_cols, drop = FALSE])

  z_indices   <- as.integer(sub("^z\\[(\\d+)\\]$", "\\1", names(z_means)))
  ordering    <- order(z_indices)
  ordered_idx <- z_indices[ordering]
  ordered_means <- z_means[ordering]

  truth_seq   <- z_local[k, ordered_idx]
  correlation <- cor(ordered_means, truth_seq)
  if (!is.na(correlation) && correlation < 0) {
    ordered_means <- 1 - ordered_means
  }

  ordered_means <- round(ordered_means)

  df_post <- data.frame(
    Time  = ordered_idx,
    MeanZ = ordered_means
  )
  df_true <- data.frame(
    Time  = seq_len(N),
    TrueZ = z_local[k, ]
  )

  p_post <- ggplot(df_post, aes(x = Time, y = MeanZ)) +
    geom_point(color = "black", size = 1) +
    labs(
      title = paste0("Arm ", k, ": Posterior Mean of P(z[t]=1)"),
      x     = "Time t",
      y     = expression(P(z[t] == 1 ~"|"~ data))
    ) +
    theme_classic(base_size = 12) +
    theme(
      plot.title = element_text(size = 10) 
    )

  p_true <- ggplot(df_true, aes(x = Time, y = TrueZ)) +
    geom_point(color = "black", size = 0.8) +
    labs(
      title = paste0("Arm ", k, ": True z[t]"),
      x     = "Time t",
      y     = "z[t]"
    ) +
    theme_classic(base_size = 12) +
    theme(
      plot.title = element_text(size = 10)  
    )

  all_plots[[2*k - 1]] <- p_post
  all_plots[[2*k    ]] <- p_true
}

grid.arrange(
  grobs = all_plots,
  ncol  = 2
)
```

